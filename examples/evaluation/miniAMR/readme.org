#+title: ~tadashi.App~ wrapper for miniAMR

* Using the ~miniAMR(App)~ class

** First steps

#+begin_src sh
  # go to miniAMR dir
  cd examples/evaluation/miniAMR/

  # download miniAMR
  ./setup.sh

  # go back to tadashi root
  cd -

  # run mini example
  PYTHONPATH=. python examples/evaluation/miniAMR/app.py
#+end_src

** Suggested usage

The ~miniAMR~ class should be imported into a python script.  It has the
usual ~tadashi.App~ methods, such as ~app.generate_code()~, ~app.compile()~,
~app.measure()~, a ~examples/evaluation/miniAMR/ml.py~

* Issues

** MiniAMR has many kernels

Not really an issue, but good to know!

The miniAMR has multiple kernels (~stencil_0()~, ~stencil_7()~,
~stencil_27()~, see ~stencil.c~ for details). You invoke miniAMR with a
~--stencil X~ flag to select the kernel which it will be running. So for
the SC submission *we need to pay make sure that we are running the
same kernel we are optimizing!*

The simples kernel is ~stencil_0()~ and currently things are set up to
optimize and run this kernel: the miniAMR C code is patched so that
~stencil_0()~ is the only SCoP detected, and running it from Tadashi
forcefully adds the ~--stencil 0~.

Also, if the runtime is too short, you can create your ~app~ like this
#+begin_src python
  app = miniAMR(run_args=["--nx", "30", "--ny", "30", "--nz", "30"])
#+end_src

** [FIXED, you can skip this] Only one SCoP

Because of some C++ issues which I need to figure out, we are
restricted to working with one SCoP in every file! I should have this
issue resolved soon.

If you pull, and rebuild which ~ninja -C build install~ this will be
fixed. But it is actually a non issue, since we probably only want to
optimiez and run only kernel ~stencil_0~.
